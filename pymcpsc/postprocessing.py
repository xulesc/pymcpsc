# This code is part of the pymcpsc distribution and governed by its
# license.  Please see the LICENSE.md file.
""" Methods for postprocessing the pairwise scores generated by the different
PSC methods in order to prepare them for performance benchmarking.

Functions:
    - *gtreadline*: read ground truth file entry
    - *norm1*: normalize given data
    - *read_psc_data*: read similarity scores from output file generated by PSC method run

Classes:
    - *PostProcessor*: class with the main run method for post-processing

A Logistic Sigmoid scheme is used to scale scores to ensure equal contribution 
of PSC methods towards the consensus MCPSC scores calculation. Given the base 
dissimilarity score ($X$) for a PSC method, its scaled  version is obtained. 
Effectively, the dissimilarity scores are  first autoscaled (to make the 
different PSC method scores comparable) and then the logistic sigmoid is 
applied. As a result, at the end we obtain similarity scores in the range 0 to 1.
"""
import matplotlib
matplotlib.use('Agg')

import os
import numpy as np
import math
from math import exp
import sys

matplotlib.rcParams['pdf.fonttype'] = 42
matplotlib.rcParams['ps.fonttype'] = 42

NO_SCALE = -1
MIN_MAX_SCALE = 0
VARIANCE_SCALE = 1
LOGISTIC_SIGMOID = 2
SCALE_TYPE = LOGISTIC_SIGMOID
DO_NORM = 0
#
V_FILE = 'violin_softmax_norm.png'


def gtreadline(line):
    """ Read ground truth file entry

    :param line: (string) Data line
    :rtype: tuple 
    """
    d = line.replace('\n', '').split('\t')
    return ((d[0], d[1]), (d[2], d[3]))


def norm1(vals):
    """ Normalize given data. higher similarity == higher value

    :param vals: (list) Data to be normalized
    :rtype: list Normalized data.
    """
    sig = np.nanstd(vals)
    mu = np.nanmean(vals)

    def f(x): return 1 - 1. / \
        (1 + math.exp(-(1.0 * x - mu) / sig)) if x is not None else x
    return list(map(lambda v: f(v), vals))


def read_psc_data(fname, idx, inv=0, sep=' '):
    """ Utility method for reading PSC method output data (pairwise scores).

    :param fname: (string) Path to data file with similarity scores
    :param idx: (int) Column index where similarity score is in the data file
    :param inv: (int) Set to 1 if score needs to be inverted (some methods output distance rather than similarity)
    :param sep: (string) Column separator
    :rtype: (dict) Pairwise normalized similarity scores
    """
    retlist = []
    for line in open(fname):
        data = line.replace('\n', '').split(sep)
        try:
            k1 = data[0].split('.')[0]
            k2 = data[1].split('.')[0]
            if data[idx] == '-0':
                continue  # this is for gr-align failed cases
            if line.find('(0.0%)') != -1:
                continue  # this is for ce failed cases
            # read front and back because we process triangular
            retlist.append(((k1, k2), abs(inv - float(data[idx]))))
            retlist.append(((k2, k1), abs(inv - float(data[idx]))))
        except:
            pass
    anp = np.array(list(map(lambda x: x[1], retlist)))
    normanp = anp  # higher similarity == lower value
    if SCALE_TYPE == MIN_MAX_SCALE:  # higher similarity == higher value
            # MinMax scaling
        normanp = list(1 - (anp - min(anp)) / (max(anp) - min(anp)))
    if SCALE_TYPE == VARIANCE_SCALE:  # higher similarity == higher value
        # Variance scaling PS (x) = exp(-s(x))/var(s)
        normanp = list(map(exp, -1 * anp / np.nanvar(anp)))
    if SCALE_TYPE == LOGISTIC_SIGMOID:
        normanp = norm1(anp)
    if SCALE_TYPE == NO_SCALE:  # higher similarity == higher value
        normanp = max(normanp) - normanp
    if DO_NORM == 1:
        normanp = list(np.array(normanp) / np.nansum(normanp))

    ret = dict(list(
        map(lambda x: (retlist[x][0], normanp[x]), range(len(normanp)))))
    return ret  # dict(retlist)


class PostProcessor:

    def run(self, config=None):
        """ Run method for post processing the data and combining PSC output for
        multiple methods into one file.

        :param config: (Config) configuration parameters for finding work, output directories etc.
        """
        print('Preparing PSC scores')
        infiles = [
            'ce_results_1.txt',
            'fast_results_1.txt',
            'gralign/results.txt.sim',
            'tm_results_1.txt',
            'usm_results.txt']
        if config is None:
            indir = 'work'
            ground_truth = 'ground_truth'
            OUTDIR = 'outdir'
        else:
            indir = config.WORKDIR  # config['indir']
            ground_truth = config.GTIN  # config['ground_truth']
            # infiles        = config['infiles']
            # methods        = config.PROGRAMS.split(',') #config['methods']
            OUTDIR = config.OUTDIR  # config['OUTDIR']

        if not os.path.exists(OUTDIR):
            os.makedirs(OUTDIR)

        if not os.path.exists('figures'):
            os.makedirs('figures')

        raw_gt = None

        # read PSC method output
        CE_INFILE, FS_INFILE, GR_INFILE, TM_INFILE, UM_INFILE = infiles
        raw_ce = read_psc_data(
            '%s%s%s' %
            (indir, os.path.sep, CE_INFILE), 7)
        raw_fs = read_psc_data(
            '%s%s%s' %
            (indir, os.path.sep, FS_INFILE), 5)
        raw_gr = read_psc_data(
            '%s%s%s' %
            (indir, os.path.sep, GR_INFILE), 6, sep='\t', inv=1)
        raw_tm = read_psc_data(
            '%s%s%s' %
            (indir, os.path.sep, TM_INFILE), 8, inv=1)
        raw_us = read_psc_data(
            '%s%s%s' %
            (indir, os.path.sep, UM_INFILE), 2)

        pp_outfile = open('%s%sprocessed.csv' % (OUTDIR, os.path.sep), 'w')
        pp_outfile.write(
            'dom1,dom2,cath1,cath2,k_r1,k_r2,k_nn1,k_nn2,ce,fast,gralign,tmalign,usm\n')

        # if ground has not been specified fake it
        if ground_truth is None:
            raw_gt = dict(map(lambda x: (x, '0.0.0.0'), set(
                raw_ce.keys() + raw_fs.keys() + raw_gr.keys() + raw_tm.keys() + raw_us.keys())))
        else:
            raw_gt = dict(map(gtreadline, open(ground_truth)))

        if sys.version_info < (3, 0):
            items = raw_gt.iteritems()
        else:
            items = raw_gt.items()

        # write pairwise scores to output file
        for k, v in items:
            # set missing values in PSC method scores to -1
            cev = raw_ce.get(k)
            if cev is None:
                cev = -1
            fastv = raw_fs.get(k)
            if fastv is None:
                fastv = -1
            grv = raw_gr.get(k)
            if grv is None:
                grv = -1
            tmv = raw_tm.get(k)
            if tmv is None:
                tmv = -1
            usmv = raw_us.get(k)
            if usmv is None:
                usmv = -1
            knn1 = v[0].split('.')[0]
            knn2 = v[1].split('.')[0]
            kr1 = '.'.join(v[0].split('.')[:4])
            kr2 = '.'.join(v[1].split('.')[:4])
            pp_outfile.write('%s,%s,%s,%s,%s,%s,%s,%s,%f,%f,%f,%f,%f\n' % (k[0], k[1], v[0], v[
                             1], kr1, kr2, knn1, knn2, max(-1, cev), max(-1, fastv), max(-1, grv), max(-1, tmv), max(-1, usmv)))
            pp_outfile.write('%s,%s,%s,%s,%s,%s,%s,%s,%f,%f,%f,%f,%f\n' % (k[1], k[0], v[1], v[
                             0], kr2, kr1, knn2, knn1, max(-1, cev), max(-1, fastv), max(-1, grv), max(-1, tmv), max(-1, usmv)))
        pp_outfile.close()
        #


if __name__ == '__main__':
    PostProcessor().run()
