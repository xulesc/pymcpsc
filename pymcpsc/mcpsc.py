# This code is part of the pymcpsc distribution and governed by its
# license.  Please see the LICENSE.md file.
"""Methods used for calculating the consensus scores.

Functions:
    - *get_wv_dataset_size*: calculates the weight vector proportional to the number of pairs processed by the PSC method
    - *get_wv_dataset_col_rmsd*: calculates the weight vector proportional to the rmsd between scores generated by PSC method pairs
    - *get_weights*: calculates the 4 standard + 1 user specified weights
    - *wmean*: calculates the weighted mean of the given values
    - *make*: main entry method
    
Generates the six standard consensus scores for each domain pair.  
"""
import os
import pandas as pd
import numpy as np


def get_wv_dataset_size(df, colnames):
    """calculates the weight vector proportional to the number of pairs processed by the PSC method.

    :param df: (dataframe) Dataframe containing the similarity scores data
    :param colname: (string) PSC methods to include in the calculations
    :rtype: (float) Weights vector for PSC methods
    """
    w1 = [len(df[x].dropna()) for x in colnames]
    return 1.0 * np.array(w1) / len(df)


def get_wv_dataset_col_rmsd(df, colnames):
    """Calculates the weight vector proportional to the rmsd between scores 
    generated by PSC method pairs.

    :param df: (dataframe) Dataframe containing the similarity scores data
    :param colname: (string) PSC methods to include in the calculations
    :rtype: (float) RMSD based weights vector for PSC methods
    """
    X = df[colnames].dropna().as_matrix()
    raw_sums = [0.0] * len(colnames)
    for _, i1 in zip(colnames, range(len(colnames))):
        for _, i2 in zip(colnames, range(len(colnames))):
            d = X[:, i1] - X[:, i2]
            raw_sums[i1] += np.dot(d, d)
    np_raw_sums = np.array(raw_sums) / (len(raw_sums) - 1)
    return np_raw_sums / max(np_raw_sums)


def get_weights(dataframe, ws_u, psc_cols):
    """Calculates the 4 standard + 1 user specified weights

    :param dataframe: (dataframe) PSC similarity scores data
    :param ws_u: (list) User defined PSC method weights
    :param psc_cols: (list) List of PSC method names to be processed
    :rtype: (list) The 5 weighted averages per PSC method
    """
    # weight vector is average of methods
    wa = np.array([1, 1, 1, 1, 1])
    # weight vector from size of dataset processed
    w1 = get_wv_dataset_size(dataframe, psc_cols)
    # weight vector from mean RMS per PSC method
    w2 = get_wv_dataset_col_rmsd(dataframe, psc_cols)
    # weight vector from main eigenvector
    # weight vector from size of dataset processed by halving USM influence
    wp = w1 * [1, 1, 1, 1, 0.5]
    # ws = [5.513287455, 2.9339976339, 5.4314202582, 11.8588931514, 0.3673017899] #scop
    # ws = [5.66859730521,2.85204498797,5.7410826929,10.7251782679,-0.508664041092] #cath
    # user supplied weights
    ws = ws_u  # [2.55,1.79,4.23,14.36,-0.38] # for proteus
    return [
        pd.Series(wa),
        pd.Series(w1),
        pd.Series(wp),
        pd.Series(w2),
        # pd.Series(w3),
        pd.Series(ws)]


def wmean(x, w):
    """Calculates the weighted mean of the given values

    :param x: (list) Values to be averaged
    :param w: (list) Weights to be applied to the values
    :return: (float) The weighted average
    """
    valid_val_idxs = ~np.isnan(x)
    _v = x[valid_val_idxs]
    _w = w[valid_val_idxs]
    _r = np.dot(_v, _w) / sum(_w)
    return _r


def make(
    outdir='outdir',
    weights_u=[
        1,
        1,
        4,
        1,
        1],
        psc_cols=[], do_user_mcpsc=True):
    """The main method for generating the consensus scores. Expects to load
    the imputed data file and writes as output a file with consensus scores
    appended for each protein domain pair.

    - **M1**: It is the Generalized Mean of the available PSC scores. In the current implementation it is essentially the average of the available PSC scores for the pair.
    - **M2**: It is a weighted average of the PSC scores of the different methods. For each domain pair we weight the available PSC method scores by the percentage of pairs successfully processed by each PSC method in the whole dataset (coverage based weighting).
    - **M3**: Similar to M2, but here we also allow domain expert knowledge to play a role in the method's relative weighting e.g. we lower USM method's weight to one half since it is a domain agnostic method (domain expert knowledge based weighting).
    - **M4**: For each domain pair, we weight each PSC method by the mean RMS distance of its scores from those of the other PSC method scores.
    - **M5**: For each domain pair, we weight the PSC methods by user supplied relative weights.
    - **M6**: Median consensus scores from (M1-M5)

    :param outdir: (string) Path to output directory where processed data files can be found
    :param weights_u: (list) List of user defined weights for the PSC methods
    :param psc_cols: (list) List of psc method names to be included in mean calculations
    :param do_user_mcpsc: (boolean) Calculate weighted average based on user specified weights
    :rtype: None
    """
    imputed_psc_cols = list(map(lambda x: '%s_fill_mean' % x, psc_cols))
    # processing
    full_psc_data = pd.read_csv(
        '%s%sprocessed.imputed.csv' %
        (outdir, os.path.sep), na_values='')
    # full_psc_data = full_psc_data.replace([-1], [None])

    print('.')
    weights = get_weights(full_psc_data, weights_u, psc_cols)
    if not do_user_mcpsc:
        weights = weights[:-1]
    # print weights

    print('.')
    wl = len(weights)

    filled_data = full_psc_data[psc_cols]
    print('.')
    colnames_full = []
    for i in range(wl):
        cname = 'mcpsc_full_%d' % i
        colnames_full.append(cname)
        # print cname
        full_psc_data[cname] = filled_data.apply(
            lambda x: wmean(np.array(x), np.array(weights[i])), axis=1)

    filled_data = full_psc_data[imputed_psc_cols]
    print('.')
    colnames_fill = []
    for i in range(wl):
        cname = 'mcpsc_fill_%d' % i
        colnames_fill.append(cname)
        # print cname
        full_psc_data[cname] = filled_data.apply(
            lambda x: wmean(np.array(x), np.array(weights[i])), axis=1)

    full_psc_data['mcpsc_full_median'] = full_psc_data[
        colnames_full].median(axis=1)
    full_psc_data['mcpsc_fill_median'] = full_psc_data[
        colnames_fill].median(axis=1)

    print('.')
    full_psc_data.to_csv(
        '%s%sprocessed.imputed.mcpsc.csv' %
        (outdir, os.path.sep))
